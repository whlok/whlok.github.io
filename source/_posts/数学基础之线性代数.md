---
title: 数学基础之线性代数
date: 2023-10-24 22:57:27
categories: 数理基础
hide: true
tags: 线性代数
---

# **第一章 行列式**

## 行列式的计算

**行列式**：不同行不同列元素乘积的代数和$det(A)$​​或$|A|$​​。

注：只有方阵才能计算行列式。当矩阵维度为$n\times n$​​，也称$n$​​阶行列式。

$|A|=\begin{vmatrix}  a_{11} \quad a_{12}\\  a_{21} \quad  a_{22} \end{vmatrix}   =a_{11} a_{22}-a_{12}a_{21}$

$|A|=\begin{vmatrix}  a_{11} \quad a_{12} \quad  a_{13}\\  a_{21} \quad  a_{22} \quad  a_{23}\\  a_{31} \quad  a_{32} \quad  a_{33} \end{vmatrix}   =a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}-a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}-a_{13}a_{22}a_{31}$

**余子式**：在![$n$](https://render.githubusercontent.com/render/math?math=n&mode=inline)阶行列式中，把元素$a_{ij}$在行列在矩阵中删去后，余下的$n-1$阶行列式叫做$a_{ij}$元素的**余子式**，记作$M_{ij}$​

**代数余子式**: $A_{ij}=(-1)^{i+j}M_{ij}$​​叫做$a_{ij}$​​​的**代数余子式**

注：余子式和代数余子式均为行列式

$A=\begin{vmatrix}  1&-2&5&0 \\  2&0&4&-1\\3&1&0&7 \\ 0&4&-2&0  \end{vmatrix}$​​        $M_{23}=$$\begin{vmatrix}  1&-2&0\\  3&1&7\\  0&4&0 \end{vmatrix}$​​     $A_{23}=(-1)^{2+3}M_{23}=(-1)^5\begin{vmatrix}  1&-2&0\\  3&1&7\\  0&4&0 \end{vmatrix}$​​

$det(A) = |A|=\begin{vmatrix}  a_{11} \quad a_{12} \quad  ... \quad a_{1n}\\  a_{21} \quad  a_{22} \quad ... \quad a_{2n} \\  \vdots \qquad  \vdots \quad  \ddots \quad \vdots \\  a_{n1} \quad  a_{n2} \quad  ... \quad a_{nn} \end{vmatrix}   = a_{i1}A_{i1}+a_{i2}A_{i2}+...+a_{in}A_{in} = a_{1j}A_{1j}+a_{2j}A_{2j}+...+a_{nj}A_{nj}$​

## 行列式性质

借助行列式的行变换性质帮我们简化运算，矩阵$A$是一个**方阵**：  

* 若$A$的某一行的**倍数加到另一行**得矩阵$B$，则$|B|=|A|$；

* 若$A$的**两行互换**得矩阵$B$，则$|B|=-|A|$​；

* 若$A$的**某行乘以$k$倍**得到矩阵$B$，则$|B|=k\cdot |A|$；

* $|A|=|A|^{T}$，这证明了行列式的列变换和行变换具有一样的效果;

* 若$A,B$​​均为$n\times n$​​矩阵，则$|AB|=|A||B|$​​. 

  ​     根据行列式的性质，我们在计算一个矩阵的行列式时，可以先对其进行一系列的行变换使其化简为阶梯型矩阵，这时直接计算对角线上的元素乘积即可，大约需要$2n^{3}/3$次运算次数。

例： $det(A)=\begin{vmatrix}  1&-4&2\\-2&8&-9 \\ -1&7&0 \end{vmatrix} = \begin{vmatrix}  1&-4&2\\0&0&-5 \\ 0&3&2 \end{vmatrix} = -\begin{vmatrix}  1&-4&2\\0&3&2 \\ 0&0&-5 \end{vmatrix}=-1*3*(-5)=15$​​​

## 克拉默法则

设$A$​​是一个可逆的$n\times n$​​矩阵，对$\Bbb{R}^{n}$​​中任意向量$\mathbf{b}$​​，方程$A\mathbf{x}=\mathbf{b}$​​的唯一解可由下式给出：$$x_{i}=\frac{|A_{i}(\mathbf{b})|}{|A|},i=1,2,\dots,n$$​​

其中$A_{i}(\mathbf{b})$​​表示$A$​​中第![$i$](https://render.githubusercontent.com/render/math?math=i&mode=inline)列由向量$\mathbf{b}$​​替换：$A_{i}(\vec{b})=\left[\vec{a_{1}} ...\vec{b} ... \vec{a_{n}}\right] \qquad\quad\quad\\@AAA\\{第i列}$​​

例：      $\begin{cases}3x_{1}-2x_{2}=6 \\
-5x_{1}+4x_{2}=8  
\end{cases}$​​

视方程为$A \mathbf{x}=\mathbf{b}$​​​​则 

$A=\left[
\begin{matrix}
   3&-2\\-5&4
  \end{matrix} 
  \right] \quad A_{1}(\vec b)= \left[
\begin{matrix}
   6&-2\\8&4
  \end{matrix} 
  \right] \quad A_{2}(\vec b)= \left[
\begin{matrix}
   3&6\\-5&8
  \end{matrix} 
  \right]$​​​​

=> $detA=2 \quad $​故此方程组有唯一解，由克拉默法则得，

$x_{1}= detA_{1}(\vec b)/detA=20\\x_{2}=detA_{2}(\vec b)/detA=27$​

注：克拉默法则对一个很大的矩阵是无效的，仅计算一个行列式就大约与用行化简解𝐴𝐱=𝐛有相同的工作量。

## 逆矩阵公式

设$A$是一个可逆的$n\times n$矩阵，则$A^{-1}=\frac{1}{|A|}adj(A)$。其中$adj(A)$为矩阵$A$​的伴随矩阵，是由代数余子式组成的矩阵的转置：

$adj(A) = \left[    \begin{array}{}      A_{11}&A_{12}& ... &A_{1n}\\  A_{21}&A_{22}& ... &A_{2n} \\  \vdots & \vdots & \ddots & \vdots \\  A_{n1}&A_{n2}& ... &A_{nn}    \end{array} \right]^T = \left[    \begin{array}{}      A_{11}&A_{21}& ... &A_{n1}\\  A_{12}&A_{22}& ... &A_{n2} \\  \vdots & \vdots & \ddots & \vdots \\  A_{1n}&A_{2n}& ... &A_{nn}    \end{array} \right]$

逆矩阵公式也印证了行列式与逆矩阵的关系：**矩阵可逆当且仅当行列式不为零**。



# 第二章 线性方程组和矩阵

## 方程组的几何解释

$$
{方程组}\begin{cases}
2x-y=0 \\
-x+2y=3  
\end{cases}
$$

### 行空间角度

$$
\left[
    \begin{array}{c}
      2&-1\\
      -1&2
    \end{array}
\right]
\left[
    \begin{array}{c}
      x\\
      y
    \end{array}
\right]
=
\left[
    \begin{array}{c}
      0\\
      3
    \end{array}
\right]
\\
\\ Ax=b
$$

**系数矩阵(A):** 将方程组系数按行提取出来，构造完成的一个矩阵。
**未知向量(x)**: 将方程组的未知数提取出来，按列构成一个向量。
**向量(b)**: 将等号右侧结果按列提取，构成一个向量。

### 列空间角度

$$
{方程组}\begin{cases}
2x-y=0 \\
-x+2y=3  
\end{cases}
$$

$$
x
\left[
    \begin{array}{c}
      2\\
      -1
    \end{array}
\right]
+
y
\left[
    \begin{array}{c}
      -1\\
      2
    \end{array}
\right]
=
\left[
    \begin{array}{c}
      0\\
      3
    \end{array}
\right]
$$

列向量构成系数矩阵，将问题转化为寻找合适的 **x，y** 使得 **x** 倍的 **(2,-1)** + **y** 倍的 **(-1,2)**得到最终的向量 **(0,3)**。

### 例：矩阵乘法

$$
A = \left[
    \begin{array}{c}
      2&5\\
      1&3
    \end{array}
\right]
,
x = \left[
    \begin{array}{c}
      2\\
      1
    \end{array}
\right]
$$

$$
方法一（行空间角度）：Ax =  \left[
    \begin{array}{c}
      2&5\\
      1&3
    \end{array}
\right]
\left[
    \begin{array}{c}
      2\\
      1
    \end{array}
\right]
= \left[
    \begin{array}{c}
      (2,5)*(1,2)\\
      (1,3)*(1,2)
    \end{array}
\right] = 
\left[
    \begin{array}{c}
      12\\
      7
    \end{array}
\right]
$$

$$
方法二（列空间角度）：Ax =  \left[
    \begin{array}{c}
      2&5\\
      1&3
    \end{array}
\right]
\left[
    \begin{array}{c}
      2\\
      1
    \end{array}
\right]
= 1\left[
    \begin{array}{c}
      2\\
      1
    \end{array}
\right] +
2\left[
    \begin{array}{c}
      5\\
      3
    \end{array}
\right] = 
\left[
    \begin{array}{c}
      12\\
      7
    \end{array}
\right]
$$

## 线性方程组

**线性方程**：包含未知数$x_{1},x_{2},\cdots,x_{n}$​​的一个**线性方程**如下所示：

​												$$a_{1}x_{1}+a_{2}x_{2}+\cdots+a_{n}x_{n}=b$$

**线性方程组**：是由一个或多个包含相同变量$x_{1},x_{2},\cdots,x_{n}$​的线性方程组成的，例如：

​										      $\begin{equation}
\begin{cases}
x_{1}-2x_{2}+x_{3}=0\\
x_{2}-4x_{3}=4\\
x_{3}=3
\end{cases} 
\end{equation}$​​​

**齐次线性方程组**：当常数项$b_{1},b_{2},,,b_{m}$ 全为0时

**非齐次线性方程组**：当常数项$b_{1},b_{2},,,b_{m}$​ 不全为0时

**解集**: 线性方程组的一组解就是一组数$(s_{1},s_{2},\cdots,s_{n})$，用这组数替代线性方程组中的$x_{1},x_{2},\cdots,x_{n}$时方程两边成立。方程组所有的解称为该线性方程组的**解集**。  

​    线性方程组包含的主要信息可以通过**矩阵**来表示，以上式为例子，可以将原方程组写为

​											$$\begin{equation}
\begin{cases}
1*x_{1}-2*x_{2}+1*x_{3}=0\\
0*x_{1}+1*x_{2}-4*x_{3}=4\\
0*x_{1}+0*x_{2}+1*x_{3}=3.
\end{cases} 
\end{equation}$$

将每一个变量的系数写在对齐的一列中，形成**系数矩阵**：

​											$$\left[
\begin{matrix}
   1 & -2 & 1\\
   0 & 1 & -4\\
   0 & 0 & 1\\
  \end{matrix} 
  \right]$$

如果我们把系数和等式右边的常数写在一个矩阵，我们称之为**增广矩阵**，如下所示：

​                                           $$\left[
\begin{matrix}
   1 & -2 & 1 & 0\\
   0 & 1 & -4 & 4\\
   0 & 0 & 1 & 3\\
  \end{matrix} 
  \right]$$​

## 矩阵消元

### 矩阵初等变换

#### 初等行变换

- （对换变换）把两行对换
- （倍加变换）把某一行换成它本身与另一行的$k$倍数的和；
- （倍乘变换）把某一行的所有元素乘以同一个非零数$k$​。

将“行”替换成列，即可得到初等列变换；初等行变换和初等列变换统称为初等变换。



如果矩阵A 经有限次初等行变换变成矩阵B，就称矩阵A 与B 行等价；

如果矩阵A 经有限次初等列变换变成矩阵B，就称矩阵A 与B 列等价；

如果矩阵A经有限次初等变换变成矩阵B，就称矩阵A与B等价.



### 消元法求解方程

​		两个线性方程组的增广矩阵行等价时，它们的解集是相同的。主要思路就是对一个矩阵进行一系列**初等行变换**，将其转换为一个**阶梯型矩阵**进而求解。

**行阶梯型矩阵**：非零矩阵若满足

（i）非零行在零行的上面；　

（ii）非零行的首非零元所在列在上一行（如果存在的话）的首非零元所在列的右面，

则称此矩阵为行阶梯形矩阵；		

阶梯型矩阵的每一行的首个非零元素我们称之为**主元**，主元所在的列称之为**主元列**。阶梯型矩阵中主元所在列，主元以下全为0；某一行的主元所在列位于前一行主元的右边。

如：

$\begin{cases}
x_{1}+2x_{2}+x_{3}=2\\
3x_{1}+8x_{2}+x_{3}=12\\
4x_{2}+x_{3}=2
\end{cases}            $$\Rightarrow$​​ $\left[
\begin{matrix}
   1 & 2 & 1 & 2\\
   3 & 8 & 1 & 12\\
   0 & 4 & 1 & 2\\
  \end{matrix} 
  \right]$

1. $row_{2}-3*row_{1}$

$\left[
\begin{matrix}
   1 & 2 & 1 & 2\\
   0 & 2 & -2 & 6\\
   0 & 4 & 1 & 2\\
  \end{matrix} 
  \right]$​

2. $row_{3}-2*row_{2}$

$\left[
\begin{matrix}
   1 & 2 & 1 & 2\\
   0 & 2 & -2 & 6\\
   0 & 0 & 5 & -10\\
  \end{matrix} 
  \right]$

3. 直至矩阵为一个阶梯型矩阵。如果消元过程中所求位置为0，则切换至下一列继续消元；过程中如果已经为阶梯型矩阵则结束算法。

​      将增广矩阵还原回线性方程组，称对应于主元列的变量$x_{1},x_{2},x_{3}$​为**基本变量**,被消去的变量称为**自由变量**

$$\left[
\begin{matrix}
   1 & 2 & 1 & 2\\
   0 & 2 & -2 & 6\\
   0 & 0 & 5 & -10\\
  \end{matrix} 
  \right]
  \begin{equation}
  \Rightarrow
\begin{cases}
x_{1}+2x_{2}+x_{3}=2\\
2x_{2}-2x_{3}=6\\
5x_{3}=-10
\end{cases} 
\end{equation}$$​​​

## 矩阵的秩

对于$n$ 阶矩阵$A$，由于$A$ 的$n$阶子式只有一个$|A|$，故当$|A|\neq 0$ 时$R(A)=n$，当$|A|=0$ 时$R(A)<n$​​. 可见可逆矩阵的秩等于矩阵的阶数，不可逆矩阵的秩小于矩阵的阶数.因此，可逆矩阵又称满秩矩阵，不可逆矩阵（奇异矩阵）又称降秩矩阵.

定理. 若$A$​~$B$​​，则$R(A)=R(B)$​​​​

推论：若可逆矩阵$P$、$Q$使得$PAQ=B$，则$R(A)=R(B)$

# **第三章 矩阵及其运算**

若$A$是$m\times n$，即有$m$行$n$列的矩阵。$A$的第$i$行第$j$列元素用$a_{ij}$表示，称为$A$的$(i,j)$元素。  

## **常见矩阵**

- 单位矩阵$I_{n}$，对角线上元素全为1，非对角线上元素全为0；
- 对角矩阵，是一个方阵，它的非对角线元素全为0。单位矩阵也是一个对角矩阵；
- 零矩阵，矩阵元素全为0。

若$A,B,C$​​是**相同维数**的矩阵，$r$​​与$s$​​为一实数，则有：

​													$A+B=B+A\\(A+B)+C=A+(B+C)\\(A+\mathbf{0})=A\\r(A+B)=rA+rB\\(r+s)A=rA+sA\\r(sA)=(rs)A\\AB\neq BA$

设$A$为$m\times n$矩阵，$B,C$维数使下列各式的乘积有定义（矩阵$A,B$​相乘，前者的列数等于后者的行数)。

关于矩阵乘法则有：

​											$A(BC)=(AB)C\\A(B+C)=AB+AC\\(B+C)A=BA+CA\\对任意实数r,r(AB)=(rA)B=A(rB)\\I_{m}A=A=AI_{m}$​

矩阵的**乘幂**表示为$A^{k}$​，其中$A$​是$n\times n$​矩阵，$A^{k}$​表示为$k$​个$A$​的乘积$A^{k}=A\cdots A$​。$A^{0}$​为单位矩阵。
矩阵的**转置**表示为$A^{T}$​，其中$A$​是一个$m\times n$​矩阵，则$A^{T}$​是一个$n\times m$​矩阵，$A^{T}$​的列是由$A$​的行构成的。设$A,B$​​为矩阵，其维数使下列和与积有定义，则有：

​														$(A^T)^T=A\\(A+B)^T=A^T+B^T\\对任意实数r,(rA)^T=rA^T\\(AB)^T=B^TA^T$​

**伴随矩阵**：若$|A|\neq 0$，则矩阵$A$可逆，且

​																		$A^{-1}=\frac{1}{|A|}A^*$

其中$A^*$为矩阵$A$ 的伴随矩阵.

## 逆矩阵

对于一个矩阵$A$来说，若存在一个矩阵$C$使得下式成立：

​															$$AC=I,CA=I$$​

那么矩阵$C$称为矩阵$A$的**逆矩阵**，若这样的$C$存在，我们称矩阵$A$是**可逆矩阵**。我们将$C$写为$A^{-1}$，于是

​														$$AA^{-1}=I,A^{-1}A=I$$​

不可逆矩阵也称之为**奇异矩阵**，可逆矩阵也称为**非奇异矩阵**。

可逆矩阵一定是方阵。
下面是有关可逆矩阵的基本定理，假设$A$​​可逆：

​										$(A^{-1})^{-1}=A\\若A，B可逆，则(AB)^{-1}=B^{-1}A^{-1}\\A^T可逆,且(A^T)^{-1}=((A)^{-1})^T$​



## 伴随矩阵求逆矩阵

假设求矩阵$A$的逆矩阵，将同维度的单位矩阵$I$与$A$构成增广矩阵$[A \quad I]$，要么有一系列行变换把$A$变成$I$，同时![$I$](https://render.githubusercontent.com/render/math?math=I&mode=inline)变成$A^{-1}$；要么$A$​是不可逆的。

例如：求$A^{-1}$

$A = \left[
\begin{matrix}
   0 & 1 & 2\\
   1 & 1 & 4\\
   2 & -1 &0\\
  \end{matrix} 
  \right] $​​ $\quad$ 

$B= [A|I] = \left[
\begin{matrix}
   0 & 1 & 2 & 1 & 0 & 0\\
   1 & 1 & 4 & 0 & 1 & 0\\
   2 & -1 &0 & 0 & 0 & 1\\
  \end{matrix} 
  \right] \Rightarrow \left[
\begin{matrix}
   1 & 0 & 0 & 2 & -1 & 1\\
   0 & 1 & 0 & 4 & -2 & 1\\
   0 & 0 & 1 & -3/2 & 1 & -1/2\\
  \end{matrix} 
  \right]$​

$A^{-1} = \left[
\begin{matrix}
   2 & -1 & 1\\
   4 & -2 & 1\\
   -3/2 & 1 &-1/2\\
  \end{matrix} 
  \right] $

伴随矩阵求逆矩阵时间复杂度过大，只适合于手算；计算机中求逆矩阵会借助矩阵的[![$LUP$](https://render.githubusercontent.com/render/math?math=LUP&mode=inline)分解](https://render.githubusercontent.com/view/《线性代数及其应用》笔记16.矩阵分解-LU分解.ipynb)。还可以通过逆矩阵公式求$A^{-1}$。



## 可逆矩阵定理

​         如果一个$n\times n$​​矩阵经过一系列行变换形成阶梯型矩阵，具有$n$​​个主元（对角线上元素均不为0），说明$|A|\neq 0$​​，再结合回[可逆矩阵定理](《线性代数及其应用》笔记03.矩阵运算与逆矩阵.ipynb)，可以得出结论：$A$​​可逆当且仅当$|A|\neq 0$​​​，可逆矩阵定理可再做补充：

$|A|\neq0\Leftrightarrow A$​可逆$\Leftrightarrow$​​​​

(1) $A\mathbf{x}=0$​仅有平凡解($\mathbf{x}=A^{-1}\mathbf{0}=\mathbf{0}$$)\Leftrightarrow$​A各列先行无关$\Leftrightarrow$​A各列生成$\Bbb{R}^n$​

(2) $A\mathbf{x}=b$​​至少有一解$\Leftrightarrow$​A有n个主元位置$\Leftrightarrow$​A等价于$n \times n$​​单位矩阵

利用可逆矩阵定理，我们可以从不同的角度去判断一个矩阵$A$是否可逆，例如给出一个矩阵$A$:

$$
A=\begin{bmatrix}
   1 & 0 & -2\\
   3 & 1 & -2\\
   -5 & -1 & 9
  \end{bmatrix}
$$

对$A$做初等行变换，判断主元个数：

​									                      $A \sim \begin{bmatrix}
   1 & 0 & -2\\
   0 & 1 & 4\\
   0 & 0 & 3
  \end{bmatrix} 
$​​

$A$​有三个主元，故$A$​是可逆的。

**逆矩阵求解方程**：若$A$可逆，则对每一个$\Bbb{R}^{n}$中的$\mathbf{b}$，方程$A\mathbf{x}=\mathbf{b}$都有唯一解：$\mathbf{x}=A^{-1}\mathbf{b}$。  

## 



# **第三章 向量**

## 向量

**定义**：$n$ 个有次序的数$a1，a2，…，an $所组成的数组称为$n$ 维向量，这$n$ 个数称为该向量的$n$ 个分量，第$i$个数$a_i$ 称为第$i$​个分量

**零向量**：所有元素都为0的向量称为零向量，用$\mathbf{0}$表示。

**向量组**：若干个同维数的列向量（或同维数的行向量）所组成的集合叫做向量组.

向量通常写为$n\times1$​列矩阵的形式，如
$$
\mathbf{u}=\begin{bmatrix}    u_{1} \\    \vdots\\    u_{n}   \end{bmatrix}
$$
**向量运算**：

（1）向量之间可以进行加减法得到新的向量（平行四边形法则）；

（2）支持和实数做标量乘法，即向量中的每个元素和该实数做乘法得到新的向量。

若$n$​​​是正整数，$\Bbb{R}^n$​​​表示所有具有![$n$](https://render.githubusercontent.com/render/math?math=n&mode=inline)个元素的向量的集合。$\Bbb{R}^2$​​​可以理解为一个平面上的直角坐标系，那么$\Bbb{R}^2$​​​中的每个向量$\mathbf{u}=\begin{bmatrix}u_{1}\\u_{2}\end{bmatrix}$​​​可看作是平面上的一个点$(u_{1},u_{2})$​​​，或者看成是平面上的一个从原点指向$(u_{1},u_{2})$​​​​​​​的有向箭头。



## 线性组合

给定$\Bbb{R}^n$​中**向量**$\mathbf{v}_{1},\mathbf{v}_{2},\cdots,\mathbf{v}_{p}$​和**标量**$c_{1},c_{2},\cdots,c_{p}$​，向量

​                               					$$\mathbf{y}=c_{1}\mathbf{v}_{1}+\cdots+c_{p}\mathbf{v}_{p}$$

称为向量$\mathbf{v}_{1},\mathbf{v}_{2},\cdots,\mathbf{v}_{p}$​以$c_{1},c_{2},\cdots,c_{p}$​为权的**线性组合**。

线性组合在几何上可以理解为是原点沿着向量的移动，也可理解为是向量伸缩后的相加，例如：

$$ \mathbf{u}=3\mathbf{v}_{1}-2\mathbf{v}_{2}=3\begin{bmatrix}-1\\1\end{bmatrix}- 2\begin{bmatrix}2\\ 1 \end{bmatrix} $$

其中$\mathbf{v}_{1},\mathbf{v}_{2}$​在$\Bbb{R}^2$​中表示如下图所示：



接着我们在图中表示出线性组合$\mathbf{u}=3\mathbf{v}_{1}-2\mathbf{v}_{2}$​的生成过程。其中左图的线性组合表示为：

原点分别沿着$3\mathbf{v}_{1}$、$-2\mathbf{v}_{2}$生成所求$\mathbf{u}$；

右图的线性组合表示为：向量$3\mathbf{v}_{1}$​、$-2\mathbf{v}_{2}$​的一次相加（平行四边形法则)。



**定理** 向量$b$​​​​​​​ 能由向量组$A：a_1,a_2,…,a_m$​​​​​​​ 线性表示的充分必要条件是矩阵$A =(a_1, a_2,… , a_m)$​​​​​​​的秩等于矩阵 $B =（a_1, a_2,…,a_m,b）$​​​​​​​的秩.

**定义** 设有两个向量组$A：a_1,a_2,…,a_m$​ 及$B =(b_1, b_2,…,b_l)$​若$B$​ 组中的每个向量都能由向量组A线性表示，则称向量组$B$​能由向量组$A$​ 线性表示.若向量组$A$​ 与向量组$B$​ 能相互线性表示，则称这两个向量组等价.

**定理** 向量组$B:b_1,b_2,...,b_l $​能由向量组$A:a_1,a_2,...,a_m$​线性表示的充分必要条件是矩阵$A=(a_1,a_2,...,a_m)$​的秩等于矩阵$(A,B)=(a_1,..,a_m,b_1,..,b_l)$的秩，即$R(A)=R(A,B)$​

**推论**　向量组$A：a_1,a_2,…,a_m$ 与向量组$B:b_1,b_2,...,b_l $能等价的充分必要条件是$R(A)=R(B)=R(A,B)$

其中$A$ 和$B$ 是向量组$A$ 和$B$​ 所构成的矩阵.



线性代数的一个**主要思想**是研究可以表示为某一固定向量集合$\{\mathbf{v}_{1},\mathbf{v}_{2},\cdots,\mathbf{v}_{p}\}$​​的线性组合的所有向量（基）。

若$\mathbf{v}_{1},\cdots,\mathbf{v}_{p}$​是$\Bbb{R}^n$​中的向量，则$\mathbf{v}_{1},\cdots,\mathbf{v}_{p}$​的所有线性组合所成的集合用记号$Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$​表示，称为由!$\mathbf{v}_{1},\cdots,\mathbf{v}_{p}$​所生成（张成）的$\Bbb{R}^n$​的子集。更具体地说，$Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$​​是所有形如：

​																				$$c_{1}\mathbf{v}_{1}+\cdots+c_{p}\mathbf{v}_{p}$$

的向量集合。特别地，一定包含零向量。
要判断向量$\mathbf{b}$是否属于$Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$，就是判断向量方程

​																			 $$x_{1}\mathbf{v}_{1}+\cdots+x_{p}\mathbf{v}_{p}=\mathbf{b}$$

是否有解，或等价地，判断增广矩阵为$\begin{bmatrix}\mathbf{v}_{1}\;\cdots\;\mathbf{v}_{p}\;\mathbf{b}\end{bmatrix}$的线性方程组是否有解。

## 向量组的线性相关性

假设$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{n}\}$为$\Bbb{R}_{n}$的一组向量，我们定义有：

- 若向量方程$x_{1}\mathbf{v}_{1}+\cdots+x_{p}\mathbf{v}_{p}=\mathbf{0}$仅有平凡解，称$\mathbf{v}_{1},\cdots,\mathbf{v}_{n}$为**线性无关**；
- 若向量方程$x_{1}\mathbf{v}_{1}+\cdots+x_{p}\mathbf{v}_{p}=\mathbf{0}$存在非平凡解$c_{1},\cdots,c_{p}$，称$\mathbf{v}_{1},\cdots,\mathbf{v}_{n}$为**线性相关**。



## 向量组的秩



## 线性方程组的解

## 向量空间

实际上我们在[向量与矩阵方程](https://render.githubusercontent.com/view/《线性代数及其应用》笔记02.向量与矩阵方程.ipynb)中已经介绍过向量空间的一些概念了，这次我们打算更深入而具体地讨论向量空间为何物。
一个**向量空间**是由一些向量构成的非空集合$V$​，在这个集合上定义了两个运算：加法和标量乘法，服从以下公理，这些公理必须对$V$​中所有向量$\mathbf{u},\mathbf{v},\mathbf{w}$​及所有标量$c,d$​成立:

### 子空间

**子空间**是由一个向量空间中适当的向量的子集所构成。在此情形下，向量空间的十个公理我们只需要验证三个，其余的自然成立。
因此我们可以说，向量空间$V$的一个子空间是$V$的一个满足性质的子集$H$:

每个子空间都是一个向量空间，每个向量空间都是一个子空间(针对本身或更大的空间而言)。特别地，向量空间$V$中仅由零向量组成的集合是$V$中一个子空间，成为零子空间，写成$\{\mathbf{0}\}$。
对两个向量空间，若其中一个在另一个内部，此时子空间这个词被使用，如下图所示，$H$为$V$的一个子空间

### 三个基本子空间

#### 零空间

满足$A\mathbf{x}=\mathbf{0}$的所有$\mathbf{x}$的集合为矩阵$A$的**零空间**，$NulA=\{\mathbf{x}:\mathbf{x}\in\Bbb{R}^{n},A\mathbf{x}=\mathbf{0}\}$。特别地，零空间也叫核空间。
要判断一个向量$\mathbf{x}$是否属于$A$的零空间，只需判断$A\mathbf{x}$是否为$\mathbf{0}$即可。
从几何上理解，矩阵$A$是一个线性变换，若$A\mathbf{x}=\mathbf{0}$说明向量$\mathbf{x}$经过了$A$线性变换后变为$\mathbf{0}$​。因此矩阵的零空间就是线性变换后落在原点的向量。例如下图所示：



#### 列空间

一个$m\times n$矩阵$A$的列向量的所有线性组合组成的向量集合称为**列空间**。
若$A=\begin{bmatrix}{}a_{1} \; \cdots \; a_{n}\end{bmatrix}$，则$ColA=Span\{a_{1},\cdots,a_{n}\}$，也可以表示为$ColA=\{\mathbf{b}:\mathbf{x}\in\Bbb{R}^{n},\mathbf{b}=A\mathbf{x}\}$。
要判断一个向量$\mathbf{v}$是否属于$A$的列空间，只需判断方程$A\mathbf{x}=\mathbf{v}$是否有解即可。故$m\times n$矩阵![$A$](https://render.githubusercontent.com/render/math?math=A&mode=inline)的列空间等于$\Bbb{R}^{m}$当且仅当方程$A\mathbf{x}=\mathbf{b}$对$\Bbb{R}^{m}$中每一个$\mathbf{b}$有一个解。
从几何上理解，矩阵$A$是一个线性变换，$A\mathbf{x}=\mathbf{b}$表明$\mathbf{b}$是由$\mathbf{x}$经过$A$线性变换后形成。因此每个位于列空间的向量都是从一个向量线性变换而来，如下图所示：

#### 行空间

一个$m\times n$​矩阵$A$​的每一行具有$n$​个元素，即可以视为$\Bbb{R}^{n}$​中的一个向量，$A$​的行向量的所有线性组合的集合称为$A$​的行空间，记作$RowA$​，易知$ColA^{T}=RowA$​。

## 基

### 基

基是刻画向量空间的基本工具，向量空间中的任何向量都可以唯一地表示成基的线性组合。
如果一个向量空间$V$和一组向量$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$满足以下条件，那么这组向量被称之为![$V$](https://render.githubusercontent.com/render/math?math=V&mode=inline)的一组**基**:

- $\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$是一组[线性无关](https://render.githubusercontent.com/view/《线性代数及其应用》笔记02.向量与矩阵方程.ipynb)集；
- $\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$生成的子空间与$V$相同，即$V=Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$.

例如，若![$A$](https://render.githubusercontent.com/render/math?math=A&mode=inline)是一个可逆的![$n\times n$](https://render.githubusercontent.com/render/math?math=n%5Ctimes%20n&mode=inline)矩阵，则由[可逆矩阵定理](https://render.githubusercontent.com/view/《线性代数及其应用》笔记04.行列式及其几何意义.ipynb)可知，![$A$](https://render.githubusercontent.com/render/math?math=A&mode=inline)的列向量组成![$\Bbb{R}^{n}$](https://render.githubusercontent.com/render/math?math=%5CBbb%7BR%7D%5E%7Bn%7D&mode=inline)的一组基。
例如，令$e_{i},\cdots,e_{n}$是$n\times n$单位矩阵$I_{n}$的列，集合$\{e_{i},\cdots,e_{n}\}$称为$\Bbb{R}^{n}$的**标准基**，如下图所示：

通常地，我们也会将基写为矩阵的形式，例如$\{\begin{bmatrix}    0\\    1   \end{bmatrix}    ,\begin{bmatrix}    1\\    0   \end{bmatrix}\}$​，写成$\begin{bmatrix}    0 \; 1\\    1 \; 0   \end{bmatrix}$​。

### 两个重要定理

**唯一表示定理**：令$\{\mathbf{b}_{1},\cdots,\mathbf{b}_{n}\}$称为$V$的一组基，则对$V$中的每个向量$\mathbf{x}$，存在唯一的一组数![$c_{1},\cdots,c_{n}$](https://render.githubusercontent.com/render/math?math=c_%7B1%7D%2C%5Ccdots%2Cc_%7Bn%7D&mode=inline)使得：

​										$\mathbf{x}=c_{1}\mathbf{b}_{1}+\cdots+c_{n}\mathbf{b}_{n}=\begin{bmatrix}    \mathbf{b}_{1} &amp; \cdots &amp; \mathbf{b}_{n}\\   \end{bmatrix} \begin{bmatrix}    c_{1} \\    \vdots \\    c_{n}   \end{bmatrix} $​​

该定理表明，向量空间中的每一个向量均可被基唯一地表示。
**生成集定理**： 令$S=\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$是$V$中的向量集，$H=Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$:

- 若$S$中某一向量（比如说$\mathbf{v}_{k}$）是$S$中其余向量的线性组合，则$S$中去掉$\mathbf{v}_{k}$后形成的向量仍可以生成$H$;
- 若$H\neq \{\mathbf{0}\}$，则$S$的某一子集是$H$的一个基。

生成集定理表明，基是一个不包含不必要向量的“高效率”的生成集。
一方面，一组向量中如果其中一个向量可以表示为其他向量的线性组合，也意味着该向量已经落在了其他向量张成的空间中，并不能为空间带来新的维度。
另一方面，一个基中的每个向量如果都为张成的空间增添新的维度，它们也称之为线性无关。一个基可以通过去掉生成集中不必要的向量生成出来。

### 零空间的基

令$NulA$是方程$A\mathbf{x}=\mathbf{0}$中所有$\mathbf{x}$的集合，要求矩阵的零空间的基，先解方程$A\mathbf{x}=\mathbf{0}$​，解方程可以通过高斯消元化为阶梯型、逆矩阵等。
我们给出例子来说明如何求矩阵零空间的基：

### 列空间的基

一个矩阵$A$被行化简为$B$时，虽然两个矩阵的列通常不同，但是$A\mathbf{x}=\mathbf{0}$与$B\mathbf{x}=\mathbf{0}$有完全相同的解集，即$A$的列和$B$的列具有**完全相同的线性相关关系**。
令$ColA$为矩阵$A$的列向量所有线性组合组成的集合，要求矩阵$A$的列空间的基，通常是将矩阵$A$行变换为阶梯型矩阵$B$​、判断主元列位置来确定基。我们给出例子来说明如何求矩阵的列空间的基。

### 行空间的基

若两个矩阵$A$和$B$等价，则它们的行空间相同。若$B$是阶梯型矩阵，则的$B$非零行构成$A$的行空间的一个基同时也是$B$的行空间的一个基。
要求一个矩阵$A$的行空间的一个基，通常是将![$A$](https://render.githubusercontent.com/render/math?math=A&mode=inline)行变换为阶梯型矩阵$B$​，判断主元位置来确定，做法和求矩阵的列空间的基相似，但是又不同。例子如下：





# **第三章 矩阵的初等变换与**

## **初等变换的性质和定理**

## **理解矩阵的秩**

### 维数

若向量空间$V$有一组基含$n$个向量，则$V$的每一组基一定恰好含有$n$个向量。
若向量空间$V$由一个有限集生成，则$V$称为有限维的，$V$的**维数**写为$dimV$，是$V$的**基向量的个数**。零向量空间$\{\mathbf{0}\}$的维数定义为零。如果$V$不是由一有限集生成的，则称$V$为无穷维的。
例如，$\Bbb{R}^{3}$的子空间可用维数分类，如下：

- 零维子空间。只有零子空间是零维子空间。
- 一维子空间。任一由单一非零向量生成的子空间，这样的子空间是经过原点的直线。
- 二维子空间。任一由两个线性无关向量生成的子空间，这样的子空间是通过原点的平面。
- 三维子空间。只有$\Bbb{R}^{3}$​本身是三维子空间，由可逆矩阵定理，$\Bbb{R}^{3}$​中任意3个线性无关向量生成整个$\Bbb{R}^{3}$​。

### 秩

矩阵$A$的秩即$A$的列空间的维数，记作$rankA$。
**秩定理**：$m\times n$矩阵$A$的列空间和行空间维数相等，这个公共的维数（即$A$的秩）还等于$A$的主元位置的个数且满足方程：

​																						$$rankA+dimNulA=n$$

也可理解为：{主元列个数}+{非主元列个数}={列的个数}。
秩定理是处理线性方程组的信息的一个有力工具。

一个矩阵如果可逆，说明有![$n$](https://render.githubusercontent.com/render/math?math=n&mode=inline)个主元，说明秩为![$n$](https://render.githubusercontent.com/render/math?math=n&mode=inline)，当一个![$n\times n$](https://render.githubusercontent.com/render/math?math=n%5Ctimes%20n&mode=inline)矩阵秩为![$n$](https://render.githubusercontent.com/render/math?math=n&mode=inline)时，称之为**满秩矩阵**

当一个矩阵秩为1，我们称它为**秩一矩阵**。秩一矩阵易于分解为一个列向量乘以一个行向量，类似$A=\mathbf{u}\mathbf{v}^{T}$​​​​​​​。
例如矩阵$A=\begin{bmatrix}{}5&8& 9\\15&24&27\end{bmatrix},B=\begin{bmatrix}2&-1 &8\\ 4&-2&16\\ 6&3&24 \end{bmatrix}$​​​​​​​​​​​​​，可以被分解为两个向量相乘：

​								$A=\begin{bmatrix}{}5&8&9\\15&24&27\end{bmatrix} = \begin{bmatrix}{}1\\3\end{bmatrix}\begin{bmatrix}{}5&8&9\end{bmatrix}$​

​								$B=\begin{bmatrix}2&-1 &8\\ 4&-2&16\\ 6&3&24 \end{bmatrix}= \begin{bmatrix}{}1\\2\\3\end{bmatrix}\begin{bmatrix}{}2&-1&8\end{bmatrix}$​

秩一矩阵可以组合为其他矩阵，例如想得到一个![$5\times 10$](https://render.githubusercontent.com/render/math?math=5%5Ctimes%2010&mode=inline)的秩为3的矩阵，可用3个不同的![$5\times 10$](https://render.githubusercontent.com/render/math?math=5%5Ctimes%2010&mode=inline)的秩一矩阵相加得到。

## **秩的性质**

## **矩阵初等变换**

## **矩阵方程**

## 矩阵的几何解释

### 线性变换

**矩阵代表了一种线性变换，矩阵乘法能将一个向量线性变换为另一个向量**。

**线性变换**，可理解为函数，它有输入有输出，输入即与矩阵相乘的向量，输出即相乘的结果。假设线性变换为![$T$](https://render.githubusercontent.com/render/math?math=T&mode=inline)，则需满足：

- 对$T$的定义域中一切$\mathbf{u},\mathbf{v}$，$T(\mathbf{u}+\mathbf{v})=T(\mathbf{u})+T(\mathbf{v})$，即$A(\mathbf{u}+\mathbf{v})=A\mathbf{u}+A\mathbf{v}$；
- 对$T$​的定义域中一切$\mathbf{u}$​和数$c$​，$T(c\mathbf{u})=cT(\mathbf{u})$​，即$A(c\mathbf{u})=cA\mathbf{u}$​​；

#### 矩阵方程与逆矩阵

解方程$A\mathbf{x}=\mathbf{b}$​，矩阵$A$​是一次线性变换，那么我们要解的$\mathbf{x}$​就是在线性变换后为$\mathbf{b}$​的向量。比如说解方程$\begin{bmatrix}0&-1\\1&0\end{bmatrix}\begin{bmatrix}\mathbf{x}_{1}\\ \mathbf{x}_{2}\end{bmatrix} =\begin{bmatrix}-2\\ 2\end{bmatrix}$​，我们需要找到与$A$​相反的线性变换将$\mathbf{b}$​再线性变换还原为$\mathbf{x}$​，与$A$​相反的线性变换就是**逆矩阵**$A^{-1}$​。比如$A$​是逆时针旋转90°，那么$A^{-1}$​就是顺时针旋转90°：

两个矩阵相乘即为两次线性变换，逆时针旋转90°后再顺时针旋转90°，当然是没有变换，$\begin{bmatrix}0 &amp; -1\\1 &amp; 0\end{bmatrix} \begin{bmatrix}0 &amp; 1\\ -1 &amp; 0\end{bmatrix}=\begin{bmatrix}1 &amp; 0\\ 0 &amp; 1\end{bmatrix}$
因此要解出$\mathbf{x}$，只需要一次相反的线性变换$A^{-1}\mathbf{b}=\begin{bmatrix}0&1\\-1&0\end{bmatrix} \begin{bmatrix}-2\\ 2\end{bmatrix}=\begin{bmatrix}2\\ 2\end{bmatrix}$。
若是方程无解呢？方程无解意味着矩阵$A$​找不到相反的线性变换，比如说：

线性变换后空间少了个维度，无法从低维的空间线性变换回高维的空间，故不存在逆矩阵，因此每个线性变换后的向量再也回不去了，方程无解。再推广一下，秩是矩阵列空间的维数，那么从几何上理解，秩就是线性变换后空间的维度，故一个满秩矩阵是可逆的。

### 非方阵

给定一个矩阵$m\times n$​，当这个矩阵与$n$​维向量做乘法时，表示将该向量从$n$​维空间映射$m$​维空间。下面分别讨论当$n>m$​或 $m>n$的情况。

例如$n>m$时$\begin{bmatrix}1&0&-2\\-1&2&-5\end{bmatrix}$​​，列空间的维数为3，拥有三个基向量，如下图所示：

当它与一个三维向量做矩阵乘法时，会得到一个二维向量，相当于是做了一次降维，将三维向量投影到二维上、将空间上的一个向量投影到这三个向量所在的平面上，例如：

$$ \begin{bmatrix}1&0&-2\\-1&2&-5\end{bmatrix}\begin{bmatrix}1 \\ 2 \\ 3 \end{bmatrix}=\begin{bmatrix}-5 \\ -12\end{bmatrix} $$​

特别地，如果是一维的情况，例如$\begin{bmatrix}1&-5\end{bmatrix}$​，就相当于是一条直线上的两个点，如图：

通过矩阵相乘来做降维是机器学习中常用的手法，例如[主成分分析法](https://render.githubusercontent.com/view/《线性代数及其应用》笔记20.主成分分析法.ipynb)。
当一个矩阵$m>n$​​时，例如$\begin{bmatrix}1&2\\0&-4\\3&-1\end{bmatrix}$​​，从几何上理解，即从三维空间取两个向量构成了一个平面，该平面与平面中的一个向量做乘法得到一个三维的向量，相当于是做了升维，将平面中的的向量投影到空间中，例如：

$$ \begin{bmatrix}1&2\\0&-4\\3&-1\end{bmatrix}\begin{bmatrix}5 \\ 6 \end{bmatrix}=\begin{bmatrix}17\\ -24\\ 9\end{bmatrix}$$

从矩阵方程$A\mathbf{x}=\mathbf{b}$​​的角度，若$n>m$，未知量数目大于方程数，方程要从一个低维的向量逆变换为一个高维的向量，要么无解，要么无穷多解；若$m>n$方程数大于未知量数，方程要从一个高维向量逆变换回一个低维向量，要么无解，要么一个解。



### 坐标系

**将矩阵乘法看成是一个函数，它的输入是一个视角下的坐标，输出是另一个视角下的坐标**

向量空间$V$​，明确指定一个基$\cal{B}$​的一个重要原因是在$V$​上强加一个坐标系。
一个向量的在不同的坐标系下有不同的坐标，描述一个坐标系最好的手段就是基。我们以$\Bbb{R}^{2}$​为例，基$\begin{bmatrix}1&0\\ 0&1\end{bmatrix}$​,$\begin{bmatrix}2&0\\ 0&2\end{bmatrix}$​,$\begin{bmatrix}2&-2\\ 0&2\end{bmatrix}$​，它们所表示的坐标系分别如下图所示，为了便于观察基向量的位置，图中还保留了横轴与竖轴，希望大家在看图的同时把它想象成是一个动图（坐标系在伸缩旋转)：

假设$\cal{B}=\{\mathbf{b}_{1},\cdots,\mathbf{b}_{n}\}$是$V$的一个基，$\mathbf{x}$在$V$中，$\mathbf{x}$相对于基$\cal{B}$的坐标是使得$\mathbf{x}=c_{1}\mathbf{b}_{1}+\cdots+c_{n}\mathbf{b}_{n}=[\mathbf{b}_{1} \cdots \mathbf{b}_{n}]\begin{bmatrix}c_{1}\\\vdots\\c_{n}\end{bmatrix}$的权$c_{1},\cdots,c_{n}$，故$\Bbb{R}^{n}$中的向量：

​																	$$[\mathbf{x}]_{\cal{B}}=\begin{bmatrix}c_{1}\\\vdots\\c_{n}\end{bmatrix}$$

是$\mathbf{x}$的$\cal{B}$坐标向量，$\mathbf{x}\mapsto [\mathbf{x}]_{\cal{B}}$​称之为**坐标映射**

从几何上解释，虽然是同一个向量，但是在不同的坐标系下所观察的“视角”不同，因而有不同的坐标。因为不同的基要去表示同一个向量所需的基向量的伸缩都是不同的。我们以向量$\begin{bmatrix}2\\2\end{bmatrix}$​为例，观察它在不同的坐标系下的差异。





通过上述例子，我们可以得到关于$[\mathbf{x}]_{\cal{B}},\cal{B}=\{\mathbf{b}_{1},\cdots,\mathbf{b}_{n}\},\mathbf{x}$三者的关系，令$P_{\cal{B}}=[\mathbf{b}_{1} \cdots \mathbf{b}_{n}]$，我们可以写成：

​																					$$\mathbf{x}=P_{\cal{B}}[\mathbf{x}]_{\cal{B}}, P_{\cal{B}}^{-1}\mathbf{x}=[\mathbf{x}]_{\cal{B}}$$

式子说明，**将矩阵乘法看成是一个函数，它的输入矩阵代表的坐标系下的坐标，输出是我们的视角下的坐标；逆矩阵则相反**。同样的向量，在不同的坐标系下具有不同的坐标，而矩阵相乘，就是将不同视角之间的坐标转换的函数。

## 

# **第六章 特征值与特征向量**

## **特征值和特征向量**

假设$A$​为$n\times n$​矩阵，$\mathbf{x}$​为非零向量，若存在数$\lambda$​使$A\mathbf{x}=\lambda \mathbf{x}$​有非平凡解$\mathbf{x}$​，则称$\lambda$​为$A$​的**特征值**（可以为零），$\mathbf{x}$​称为对应于$\lambda$​的**特征向量**（非零）。

若$\lambda$为矩阵$A$的特征值，那么方程：

$$(A-\lambda I)\mathbf{x}=\mathbf{0}$$

中所有解的集合（$A-\lambda I$的零空间）称为$A$的对应于$\lambda$​的**特征空间**。 

直观地，设$A=\begin{bmatrix}1 & 6\\5 & 2\end{bmatrix}$,$\mathbf{u}=\begin{bmatrix}6\\-5\end{bmatrix} $,$\mathbf{v}=\begin{bmatrix}3\\-2\end{bmatrix}$，计算有：

$$
A\mathbf{u}=\begin{bmatrix}-24\\20\end{bmatrix}=-4\begin{bmatrix}6\\
-5
\end{bmatrix}=4\mathbf{u},A\mathbf{v}=\begin{bmatrix}-9\\
11
\end{bmatrix}\neq \lambda\begin{bmatrix}3\\
-2\end{bmatrix}
$$

因此$\mathbf{u}$​是特征值-4对应的特征向量，但$\mathbf{v}$​不是$A$​的特征向量。

我们考虑特征值为零的情况，当矩阵$A$有零特征值时，方程：

$$A\mathbf{x}=\mathbf{0}\mathbf{x}$$

有非平凡解，说明矩阵$A$不可逆，因此可以下一个结论：**0是矩阵$A$的特征值当且仅当$A$不可逆**。  

### 特征方程求特征根

给定一个$n\times n$的矩阵$A$，如何求特征值和对应的特征向量？  

特征值$\lambda$需满足方程$A\mathbf{x}=\lambda \mathbf{x}$中的$\mathbf{x}$有解存在，也即方程：

$$(A-\lambda I)\mathbf{x}=\mathbf{0}$$

有非零解存在，根据可逆矩阵定理，若矩阵$A-\lambda I$线性无关，则方程只有零解，因此要使方程有解，矩阵$A-\lambda I$不可逆，也即行列式$|A-\lambda I|$等于0。  

引出定理：数$\lambda$是$n\times n$矩阵$A$的特征值的充要条件为$\lambda$是**特征方程**$|A-\lambda I|=0$​的根。

举例如下：

可以发现**特征方程**$|A-\lambda I|=0$是关于$\lambda$的的多项式，也称之为$\lambda$​的特征多项式。  

还可以应用[QR分解](《线性代数及其应用》笔记17.矩阵分解-QR分解.ipynb)来求矩阵的特征值。

### 应用

下面通过一个例子来说明特征值和特征向量的作用：

### 几何意义

矩阵是一次[线性变换](《线性代数及其应用》笔记08.矩阵的几何解释-线性变换.ipynb)，

那么特征向量就是在线性变换前后、只做了伸缩未改变方向的向量，

而特征值就是伸缩的比例，当特征值为负表明特征向量被反向拉伸。

## **相似矩阵**

假设$A,B$是$n\times n$矩阵，如果存在可逆矩阵$P$使得$P^{-1}AP=B$，或等价地$A=PBP^{-1}$，则称$A$**相似**于$B$。把$A$变成$P^{-1}AP$的变换称为**相似变换**

若$n\times n$矩阵$A,B$是相似的，那么它们有相同的特征多项式，从而有相同的特征值。 
结合回[线性变换](《线性代数及其应用》笔记08.矩阵的几何解释-线性变换.ipynb)和[坐标系](《线性代数及其应用》笔记09.矩阵的几何解释-坐标系.ipynb)的内容，我们来思索为什么$P^{-1}AP=B$称$A,B$相似。  

我们知道矩阵可以代表一种线性变换，也能代表一个坐标系。在我们的视角下作一次线性变换很简单，只需要记录基向量变换后的位置即可，例如下图所示做了一次逆时针旋转90°：

但是如果是在别的视角下的呢？我们希望在$\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}$的视角下做逆时针旋转90°，如下图所示：

做法和之前[线性变换](《线性代数及其应用》笔记08.矩阵的几何解释-线性变换.ipynb)是相同的，只是我们很难从$\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}$的视角下去观察逆时针旋转90°后所处的坐标，我们需要通过矩阵相乘转换成我们的视角下。  



比如$\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}$视角下有个向量$\begin{bmatrix}x\\y\end{bmatrix}$，我们希望得到它经过逆时针90°旋转后的坐标。先将其转换成我们的视角下：

接着在我们的视角下作一次逆时针旋转90°：

最后是乘以逆矩阵还原回原来的视角：

由此可以看出$A=\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}^{-1}\begin{bmatrix}0 & -1\\
1 & 0
\end{bmatrix}\begin{bmatrix}2 & -2\\
0 & 2
\end{bmatrix}$其实就是在$\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}$的视角下做$\begin{bmatrix}0 & -1\\1 & 0\end{bmatrix}$变换，故$A$与$B=\begin{bmatrix}0 & -1\\1 & 0\end{bmatrix}$可以说是相似的，因为他们都其实是逆时针旋转90°，只是一个在我们的视角下，一个是在$\begin{bmatrix}2 & -2\\ 0 & 2\end{bmatrix}$的视角下。  

这也能解释为什么相似矩阵具有相同的特征值，因为本质上都是同一种变换。  

## 对角化

如果方阵$A$相似于对角矩阵，即存在可逆矩阵$P$和对角矩阵$D$，有$A=PDP^{-1}$，则称$A$可**对角化**。  

**对角化定理**：$n\times n$矩阵$A$可对角化的充要条件是$A$有$n$个线性无关的特征向量，这$n$个特征向量我们称之为**特征向量基**。若$A$可对角化，则$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的主对角线上元素是$A$的对应于$P$​中特征向量的特征值，证：

### 矩阵对角化流程

下面通过一个例子来说明如何对一个矩阵对角化。流程如下：

### 矩阵对角化与幂

矩阵对角化相当于是矩阵分解，它最大的作用是求矩阵的幂运算。推导：

而对角矩阵的幂运算又非常简单，例如：

## **实对称矩阵**

## 内积与范数

### 内积

假设$\mathbf{u},\mathbf{v}$是$\Bbb{R}^{n}$中的向量，则称$\mathbf{u}\cdot \mathbf{v}$为$\mathbf{u}$和$\mathbf{v}$的**内积**，计算如下：

$$\mathbf{u}\cdot\mathbf{v}=\mathbf{u}^{T}\mathbf{v}=[u_{1}\cdots u_{n}]\begin{bmatrix}
v_{1}\\
\vdots\\
v_{n}
\end{bmatrix}=u_{1}v_{1}+\cdots+u_{n}v_{n}$$​

内积具有如下性质，其中$\mathbf{u},\mathbf{v},\mathbf{w}$是$\Bbb{R}^{n}$中的向量，$c$​是一个数：



内积也可以写成如下形式，其中$\theta$为$\mathbf{u},\mathbf{v}$向量之间的夹角：$\mathbf{u}\cdot \mathbf{v}=\Vert\mathbf{u}\Vert\Vert\mathbf{v}\Vert cos\theta$。
这也是内积的几何意义，即$\mathbf{u}$投影到$\mathbf{v}$的长度乘以$\mathbf{v}$​的长度：

### 范数

各种范数如下：

* **向量的0-范数**：向量的非零元素个数，记作$\Vert\mathbf{x}\Vert_{0}$，可理解为$\mathbf{x}$到原点的汉明距离。
* **向量的1-范数**：向量的元素绝对值之和，记作$\Vert\mathbf{x}\Vert_{1}=\sum_{i=1}^n|x_{i}|$，可理解为$\mathbf{x}$到原点的曼哈顿距离。
* **向量的2-范数（向量的长度/范数）**：向量的元素平方和再开方，恰好为与自身的内积再开方，即$\Vert\mathbf{x}\Vert=\sqrt{\mathbf{x}\cdot\mathbf{x}}=\sqrt{x_{1}^{2}+\cdots+x_{n}^{2}}$，$\Vert\mathbf{x}\Vert^{2}=\mathbf{x}\cdot\mathbf{x}$，可理解为$\mathbf{x}$到原点的欧式距离。
* **向量的p-范数**：向量元素绝对值的p次方和的1/p次幂，记作$\Vert\mathbf{x}\Vert_{p}=(\sum_{i=1}^n|x_{i}|^{p})^{\frac{1}{p}}$
* **矩阵的1-范数**：返回矩阵的每个列向量的1-范数中的最大值。
* **矩阵的2-范数**：$\Vert X\Vert_{2}=\sqrt{\lambda_{1}}$，其中$\lambda_{1}$为$X^{T}X$的最大特征值。 

对任意数$c$，向量$c\mathbf{x}$的长度等于$\Vert c\mathbf{x}\Vert=|c|\Vert\mathbf{x}\Vert$。  

长度为1的向量我们称之为**单位向量**，单位化是指将向量$\mathbf{u}$化为单位向量$\mathbf{v}$的过程，即$\mathbf{v}=\mathbf{u}/\Vert\mathbf{u}\Vert$，其中$\mathbf{u},\mathbf{v}$方向一致。  

**两个向量之间的距离**：$\Bbb{R}^{n}$中两个向量$\mathbf{u},\mathbf{v}$之间的距离记作$dist(\mathbf{u},\mathbf{v})$，表示向量$\mathbf{u}-\mathbf{v}$的长度，即$dist(\mathbf{u},\mathbf{v})=\Vert\mathbf{u}-\mathbf{v}\Vert$​；可推广计算：

即满足平方差定理。

## 正交与正交基

### 正交

考虑$\Bbb{R}^{2}$或$\Bbb{R}^{3}$中通过原点且由向量$\mathbf{u},\mathbf{v}$确定的两条直线，两条直线几何上垂直当且仅当$dist(\mathbf{u},\mathbf{v})=dist(\mathbf{u},-\mathbf{v})$，如下图所示：

推导得

 $[dist(\vec{v},\vec{u})]=\left \|\vec{v}-\vec{u}  \right \|^2 = \left \|\vec{v}  \right \|^2 + \left \|\vec{u}\right \|^2-2\vec{v} \cdot \vec{u}$​

 $[dist(\vec{v},\vec{-u})]=\left \|\vec{v}+\vec{u}  \right \|^2 = \left \|\vec{v}  \right \|^2 + \left \|\vec{u}\right \|^2+2\vec{v} \cdot \vec{u}$

得出结论：$\Bbb{R}^{n}$中两个向量$\mathbf{u},\mathbf{v}$相互**正交**（垂直）的充要条件是$\mathbf{u}\cdot\mathbf{v}=0$。零向量与任何向量都正交。  

**勾股定理**：两个向量正交的充要条件是

$\Vert\mathbf{u}+\mathbf{v}\Vert^{2}=\Vert\mathbf{u}\Vert^{2}+\Vert\mathbf{v}\Vert^{2}$，如下图所示：





### 正交补

如果向量$\mathbf{z}$与$\Bbb{R}^{n}$的子空间$W$中的任意向量都正交，则称$\mathbf{z}$正交于$W$；与$W$正交的全体向量的集合称为$W$的**正交补**$W^{\bot}$。向量$\mathbf{x}$属于$W^{\bot}$的充要条件是向量$\mathbf{x}$与生成空间$W$的任一向量正交。

假设$A$是$m\times n$矩阵，那么$A$的行空间的正交补是$A$的零空间，且$A$的列空间的正交补是$A^{T}$的零空间（因为零空间的每个向量与$A$的每个行向量正交）：

### 正交基

**正交集**：如果$\Bbb{R}^{n}$中的向量集合$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{n}\}$中任意两个不同向量都正交，则被称之为正交集。  

**正交基**：如果$S=\{\mathbf{u}_{1},\cdots,\mathbf{u}_{n}\}$是由$\Bbb{R}^{n}$中非零向量构成的正交集，那么$S$是线性无关集，因此构成$S$所生成的一组正交基。  

**单位正交集**：由单位向量构成的正交集集合$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{p}\}$称之为单位正交集。如果$W$是一个由单位正交集生成的子空间，那么$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{p}\}$是$W$的单位正交基或标准正交基。  

正交基相较于其他基更有优越性，更易计算线性组合中的权。  

假设$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{p}\}$是$\Bbb{R}^{n}$中子空间$W$的正交基，对$W$中的每个向量$\mathbf{y}$，线性组合：
$$\mathbf{y}=c_{1}\mathbf{u}_{1}+\cdots+c_{p}\mathbf{u}_{p}$$
中的权可以由$c_{j}=\frac{\mathbf{y}\cdot\mathbf{u}_{j}}{\mathbf{u}_{j}\cdot\mathbf{u}_{j}}(j=1,\cdots,p)$计算，所以有：
$$\mathbf{y}=\frac{\mathbf{y}\cdot\mathbf{u}_{1}}{\mathbf{u}_{1}\cdot\mathbf{u}_{1}}\mathbf{u}_{1}+\cdots+\frac{\mathbf{y}\cdot\mathbf{u}_{p}}{\mathbf{u}_{p}\cdot\mathbf{u}_{p}}\mathbf{u}_{p}$$

证明如下：

## 正交分解定理

若$W$是$\Bbb{R}^{n}$的一个子空间，那么$\Bbb{R}^{n}$中的每一个向量$\mathbf{y}$可以唯一地表示为：

$$\mathbf{y}=\hat{\mathbf{y}}+\mathbf{z}$$

其中$\hat{\mathbf{y}}$属于$W$而$\mathbf{z}$属于$W^{\bot}$，实际上，如果$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{p}\}$是$W$的任意正交基，那么：

$$\hat{\mathbf{y}}=\frac{\mathbf{y}\cdot\mathbf{u}_{1}}{\mathbf{u}_{1}\cdot\mathbf{u}_{1}}\mathbf{u}_{1}+\cdots+\frac{\mathbf{y}\cdot\mathbf{u}_{p}}{\mathbf{u}_{p}\cdot\mathbf{u}_{p}}\mathbf{u}_{p}$$

且$\mathbf{z}=\mathbf{y}-\hat{\mathbf{y}}$。$\hat{\mathbf{y}}$称为$\mathbf{y}$在$W$上的正交投影，记作$proj_{W}\mathbf{y}$，如下图所示：

## 最佳逼近定理

假设$W$是$\Bbb{R}^{n}$的一个子空间，$\mathbf{y}$是$\Bbb{R}^{n}$中的任意向量，$\hat{\mathbf{y}}$是$\mathbf{y}$在$W$上的正交投影，那么$\hat{\mathbf{y}}$是$W$中最接近$\mathbf{y}$的点，也就是：

$$\Vert\mathbf{y}-\hat{\mathbf{y}}\Vert<\Vert\mathbf{y}-\mathbf{v}\Vert$$

对所有属于$W$又异于$\hat{\mathbf{y}}$的$\mathbf{v}$成立。可理解为向量$\hat{\mathbf{y}}$为$W$中元素对$\mathbf{y}$​的**最佳逼近**。  

## 正交矩阵

各列构成单位正交集的矩阵在应用和用矩阵计算的计算机算法中都非常重要，这样的矩阵我们也称之为**正交矩阵**。  

**定理**：一个$m\times n$矩阵$U$具有单位正交列向量的充要条件是$U^{T}U=I$。证明如下：



易知，如果一个正交矩阵$U$可逆（具有单位正交列的方阵），则它的逆矩阵为$U^{T}$​，例如：
$$
U=\begin{bmatrix}
   0 & 1 & 0\\
   1 & 0 & 0\\
   0 & 0 & 1
  \end{bmatrix} 
  , U^{T}=
\begin{bmatrix}
   0 & 1 & 0\\
   0 & 0 & 1\\
   1 & 0 & 0
  \end{bmatrix}
$$
**定理**：如果$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{p}\}$是$\Bbb{R}_{n}$中子空间$W$的单位正交基，那么：

$$proj_{W}\mathbf{y}=\frac{\mathbf{y}\cdot\mathbf{u}_{1}}{\mathbf{u}_{1}\cdot\mathbf{u}_{1}}\mathbf{u}_{1}+\cdots+\frac{\mathbf{y}\cdot\mathbf{u}_{p}}{\mathbf{u}_{p}\cdot\mathbf{u}_{p}}\mathbf{u}_{p}=(\mathbf{y}\cdot\mathbf{u}_{1})\mathbf{u}_{1}+\cdots+(\mathbf{y}\cdot\mathbf{u}_{p})\mathbf{u}_{p}$$

如果$U=[\mathbf{u}_{1} \cdots \mathbf{u}_{p}]$，则：

$$proj_{W}\mathbf{y}=UU^{T}\mathbf{y}$$​  

该定理说明了一个空间的单位正交基的优越性，可以很简单地表达出任意向量在该空间的正交投影。  

## 格拉姆-施密特方法

我们说明了正交矩阵、单位正交基的种种好处，而**格拉姆-施密特方法**是对$\Bbb{R}_{n}$中任何非零子空间构造正交基或标准正交基的简单算法，该算法基于[正交分解定理](《线性代数及其应用》笔记14.正交分解定理与最佳逼近定理.ipynb)，逐个使基向量$\mathbf{x}_{k}$分解为正交于前$k$个基向量的向量。对$\Bbb{R}^{n}$的子空间$W$的一个基$\{\mathbf{x}_{1},\cdots,\mathbf{x}_{p}\}$，其中$proj_{W_{k}}\mathbf{x}_{k+1}$表示$\mathbf{x}_{k+1}$在$Span\{\mathbf{x}_{1},\cdots,\mathbf{x}_{k}\}$​的正交投影，算法过程为：



那么得到的向量集合$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{p}\}$是$W$的一个正交基，此外$Span\{\mathbf{v}_{1},\cdots,\mathbf{v}_{k}\}=Span\{\mathbf{x}_{1},\cdots,\mathbf{x}_{k}\}$,其中$1\leq k\leq p$。举一个简单的小例子：

## 矩阵分解

### LU分解

分解要求：矩阵各列线性无关。

矩阵的因式分解是把A表示为两个或更多矩阵的乘积，矩阵乘法是数据的综合（把两个或更多线性变换的作用结合成一个矩阵），矩阵的因式分解是数据的分解，把数据组成两个或者更多，这种结构可能更有用，或者更便于计算。  

在工业与商业问题中，$LU$​分解是常见的一种矩阵因式分解算法，用途在于解一系列具有相同系数矩阵中的线性方程：

$A\vec{x}=\vec{b_{1}} \\A\vec{x}=\vec{b_{2}} \\ ...\\A\vec{x}=\vec{b_{p}}$

我们假设$m\times n$矩阵$A$可以行化简为阶梯型矩阵而**不必进行行变换**（可对比$LUP$分解），则$A$可以写成形式$A=LU$，$L$是$m\times n$下三角矩阵（可逆），主对角线元素全是1；$U$是$A$的一个等价的$m\times n$​​阶梯型矩阵，如下图所示：

$A=\begin{bmatrix}
   1 & 0 & 0 &0\\
   "*" & 1 & 0&0\\
   0 & 0 & 1
  \end{bmatrix}$​​​

通过$LU$分解求解$A\mathbf{x}=\mathbf{b}$可以写成$LU\mathbf{x}=\mathbf{b}$，可变换成解下列方程来求解$\mathbf{x}$：

先解(1)再(2)，因为$L,U$都是三角矩阵，因此很容易计算。  

#### 算法流程

1. 矩阵$A$经过一系列初等行变换变成阶梯型矩阵，即$U$;
2. 换过程在每个主元列，把主元以下的元素除以主元即为$L$​在该列主元以下的元素。  

#### 算法性能分析

下列运算次数的计算适用于$n\times n$稠密矩阵$A$（大部分元素非零），$n$相当大，例如$n\geq 30$。

1. 计算$A$的$LU$分解大约需要$2n^{3}/3$浮算，而求$A^{-1}$大约需要$2n^{3}$浮算。
2. 解$L\mathbf{y}=\mathbf{b}$和$U\mathbf{x}=\mathbf{y}$大约需要$2n^{3}$浮算，因为任意$n\times n$三角方程组可以用大约$n^{3}$浮算解出。
3. 把$\mathbf{b}$乘以$A^{-1}$也需要$2n^{3}$浮算，但结果可能不如$L$和$U$得出的精确(由于计算$A^{-1}$及$A^{-1}\mathbf{b}$的舍入误差)。
4. 若$A$是稀疏矩阵（大部分元素为0），则$L$和$U$可能也是稀疏的，然而$A^{-1}$很可能是稠密的，显然用$LU$分解来解$A\mathbf{x}=\mathbf{b}$很可能比用$A^{-1}$快很多。  

#### LUP分解

考虑下面一个矩阵的$LU$分解：

$$A=\begin{bmatrix}
   2 & 4 & -1\\
   0 & 0 & 3\\
   0 & -5 & -4
  \end{bmatrix} 
$$
根据之前所述算法，先将矩阵$A$化为阶梯形矩阵，并在变换的过程中求出$L$。但是很明显，在这种情况下，会出现除数为0的情况，这当然是灾难性的。  

除了除数为0外，还有除数很小的情况，这会产生数值不稳定，因此我们希望尽可能选一个较大的主元。所以有的时候我们必须在矩阵的非对角线元素中选主元。  

我们先引入一个**置换矩阵**的概念，考虑下面两个矩阵的相乘：

根据我们之前所学知识很容易解出来，求得：

$$A=\begin{bmatrix}
   2 & 4 & -1\\
   0 & -5 & -4\\
   0 & 0 & 3
  \end{bmatrix}
$$

可以发现，矩阵$A$似乎没什么变化，只是行的位置改变了而已。我们把这样的矩阵称之为**置换矩阵**。置换矩阵是一种系数只由0和1组成的方阵。矩阵的每一行/列的第$i$个元素为1，表示原矩阵的该行/列为第$i$行/列。具体置换的行or列取决于是左乘还是右乘：

 * 当矩阵$A$左乘一个置换矩阵，交换的是矩阵的行。即$P\cdot A$;
 * 当矩阵$A$右乘一个置换矩阵，交换的是矩阵的列。即$A\cdot P$.

让我们回到$LUP$分解。借助这个置换矩阵，我们可以将矩阵$A$的行进行置换，每步重新选取较大的主元进行行替换。原来的$A=LU$我们改写为$PA=LU$，其中$P$是一个置换矩阵。该式子表示为先对$A$进行行置换，再对行置换后的$A$进行$LU$分解。  

当我们要求解$A\mathbf{x}=\mathbf{b}$，可做如下变换：

于是问题可以变换为：

求解到的$\mathbf{x}$就是$A\mathbf{x}=\mathbf{b}$的解，证明如下：

其实$LU$分解是$LUP$分解的一种，当$P=I$时，$LUP$分解就成为$LU$分解。可以理解成是$A$矩阵不进行置换的情况下$LUP$分解就成为了$LU$分解。

#### 应用

利用好矩阵的因式分解，不只是在求解方程组，在求逆矩阵、最小二乘逼近方面也能大大提高效率。目前计算机在计算矩阵的逆都是采用$LU$​分解。

在求逆矩阵时，我们可以有两种思路：

通过$LUP$分解来求逆矩阵的过程中，分解的过程需要$O(n^{3})$，求解三角矩阵的过程需要$O(n^{2})$，避免了主元素为0的情况。可提高求解一系列具有相同系数矩阵中的线性方程的效率。  

### QR分解

#### 介绍

​        如果$m\times n$矩阵$A$的列线性无关，那么$A$可以分解为$A=QR$，其中$Q$是一个$m\times n$矩阵，其列形成$ColA$的一个[标准正交基](《线性代数及其应用》笔记13.正交与正交基.ipynb)，$R$是一个$n\times n$上三角可逆矩阵且在对角线上的元素为正数。$QR$​​分解常用于求解[特征值](《线性代数及其应用》笔记10.特征值和特征向量.ipynb)以及[最小二乘求解](《线性代数及其应用》笔记19.最小二乘法.ipynb)。  

对$m\times n$矩阵$A$做$QR$分解步骤如下：

* 对$A$的列向量应用[格拉姆-施密特方法](《线性代数及其应用》笔记15.正交矩阵与格拉姆-施密特方法.ipynb)得到一组正交基，再单位化后得到单位正交基，单位正交基构成矩阵Q的列；
* 可知$Q^{T}Q=I$（正交矩阵的定理），所以有$Q^{T}A=Q^{T}QR=R$，因此计算$Q^{T}A$即可得到$R$​。  



#### QR分解求特征值

QR$分解被广泛地用来估计一般矩阵$A$的特征值。算法流程如下：  

1. $A$被分解为$Q_{1},R_{1}$，计算$R_{1}Q_{1}$得到$A_{1}$；
2. $A_{1}$被分解为$Q_{2},R_{2}$，计算$R_{2}Q_{2}$得到$A_{2}$；  
3. 以此类推，计算到第$k$次时，$A_{k}$几乎是上三角的，且对角线上单元素近似于$A$的特征值。  

可以简单地证明，$A$是相似于$A_k$的

通过𝑄𝑅QR分解计算出来的矩阵除对角线外元素更趋于0；通过𝑄𝑅QR分解计算得到的矩阵对角线上元素均趋于特征值。

### 奇异值分解

分解条件：条件最低，任何矩阵都有可能。

#### 正交对角化

**对称矩阵**是一个满足$A^{T}=A$的矩阵$A$。自然地，对称矩阵是一个方阵。  

**定理**：如果$A$是对称矩阵，那么不同特征空间的任意两个特征向量是正交的。（补充：无论是不是对称矩阵，相异的特征值对应的特征向量组成的集合都是线性无关的）证：





我们知道，[对角化](《线性代数及其应用》笔记11.矩阵相似与对角化.ipynb)是对于一个方阵$A$，能找到$n$个线性无关的特征向量组成的矩阵$P$、特征值组成的对角矩阵$D$使得$A=PDP^{-1}$。而当$P$为正交矩阵，则称上式为**正交对角化**。我们再引出**定理**：一个$n\times n$矩阵$A$可正交对角化的充要条件是$A$是对称矩阵。  





#### 奇异值分解介绍

对角化在许多应用中都很重要，但是要对一个矩阵进行对角化，该矩阵必须是方阵。下面将介绍另一种矩阵分解：**奇异值分解**，该分解对任意$m\times n$矩阵$A$都有可能，是线性代数应用中最有用的矩阵分解，被用于求矩阵的秩、降维、压缩图像等。  
$\quad$奇异值分解的形式如下：

$$A=U\varSigma V^{T}$$

其中$U$为$m\times m$正交矩阵，$V$为$n\times n$正交矩阵，$U$的列称为$A$的左奇异向量，$V$的列称为$A$的右奇异向量；$\varSigma$为$m\times n$”对角矩阵“，$D$为一个$r\times r$对角矩阵，$\sigma_{1},\cdots,\sigma_{r}$为矩阵的$r$个奇异值，形式如下：



#### 奇异值分解算法

​		令矩阵$A$为$m\times n$矩阵，我们希望得到$A$的奇异值分解$A=U\varSigma V^{T}$，接下来会从这个式子出发，逐步推出$U,\varSigma,V$​的求解方法以及之间的关系。  

##### 结论一

我们计算$A^{T}A,AA^{T}$有：

形式与对角化是一致，其中而对称矩阵是可以正交对角化的，为此可以下一个结论：$A^{T}A$以及$AA^{T}$的特征向量规范化（指化为单位正交基）后可构成$V$和$U$，特征值的非零项开方称之为**奇异值**，记作$\sigma_{i}$，奇异值构成$\varSigma$。

##### 结论二

令$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{n}\}$是$\Bbb{R}^n$的单位正交基且构成$A^{T}A$的特征向量，$\lambda_{1},\cdots,\lambda_{n}$是$A^{T}A$对应的特征值，那么我们有:

这里得到两个结论：  

* 奇异值非负；
* $\{\mathbf{v}_{1},\cdots,\mathbf{v}_{n}\}$为$A^{T}A$的特征向量，$A$的奇异值是向量$A\mathbf{v}_{1},\cdots,A\mathbf{v}_{n}$的长度. 

##### 结论三

我们对奇异值分解的式子变换如下：
$$AV=U\varSigma$$
我们将其展开：

是奇异值、原矩阵、左右奇异向量的关系，在我们通过结论一求出了奇异值、其中一个奇异向量时，可以直接求出另一个奇异向量。通过这些知识我们已经可以对A进行奇异值分解了。 

#### 应用

##### 矩阵求秩

计算机估计大矩阵$A$的[秩](《线性代数及其应用》笔记07.维数和秩.ipynb)时，最可靠的方法就是计算非零奇异值的个数（特别小的非零奇异值在实际计算中假定为0），可参考MATLAB的rank源码。  
$\quad$**定理一**：假若$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{n}\}$是包含$A^{T}A$的特征向量的$\Bbb{R}^{n}$上的单位正交基，重新整理使得对应的$A^{T}A$的特征值满足$\lambda_{1}\geq\cdots\geq\lambda_{n}$。假如$A$有$r$个非零奇异值，那么$\{A\mathbf{v}_{1},\cdots,A\mathbf{v}_{r}\}$是$ColA$的一个正交基，且$rankA=r$。  
$\quad$定理一说明了，矩阵的奇异值的个数即为矩阵的秩。我们结合结论三得出定理二：  
$\quad$**定理二**：给定$m\times n$矩阵$A$的一个奇异值分解，取$\mathbf{u}_{1},\cdots,\mathbf{u}_{m}$是左奇异向量，$\mathbf{v}_{1},\cdots,\mathbf{v}_{n}$是右奇异向量，且$\sigma_{1},\cdots,\sigma_{n}$是奇异值，$r$为$A$的秩；$\{\mathbf{u}_{1},\cdots,\mathbf{u}_{r}\}$是$ColA$的一个单位正交基，$\{\mathbf{v}_{r+1},\cdots,\mathbf{v}_{n}\}$是$NulA$的一个单位正交基，$\{\mathbf{v}_{1},\cdots,\mathbf{v}_{r}\}$是$RowA$的一个单位正交基。  
$\quad$上述的两条定理表明了奇异值个数、列空间、行空间、零空间之间的关系。举一个例子：

##### 图像压缩

$\quad$我们知道一个图像其实就是一个矩阵，矩阵上每个元素都代表着像素。  
$\quad$假设$A$为一个$m\times n$矩阵，对$A$做奇异值分解有：$A=U\varSigma V^{T}$，我们展开计算有：

其中$\sigma_{i}$按照从大到小排列，$\mathbf{u}_{i}\mathbf{v}_{i}^T$为一个秩一矩阵。我们知道，$r$个不同的秩一矩阵相加得到的矩阵秩为$r$，可得到两个结论：  

1. $A$的奇异值个数为$A$的秩；
2. 每个奇异值可看作是一个秩一矩阵的权重。  

$\quad$奇异值一般数值间差异很大，我们可以取前$k$项来近似等于$A$从而压缩：

# **第七章 二次型**

## **二次型及矩阵表示**

## **二次型的标准型**

## **二次型的正定**

